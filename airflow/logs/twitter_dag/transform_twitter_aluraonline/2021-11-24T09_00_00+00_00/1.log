[2021-11-29 23:35:27,470] {taskinstance.py:670} INFO - Dependencies all met for <TaskInstance: twitter_dag.transform_twitter_aluraonline 2021-11-24T09:00:00+00:00 [queued]>
[2021-11-29 23:35:27,478] {taskinstance.py:670} INFO - Dependencies all met for <TaskInstance: twitter_dag.transform_twitter_aluraonline 2021-11-24T09:00:00+00:00 [queued]>
[2021-11-29 23:35:27,478] {taskinstance.py:880} INFO - 
--------------------------------------------------------------------------------
[2021-11-29 23:35:27,478] {taskinstance.py:881} INFO - Starting attempt 1 of 1
[2021-11-29 23:35:27,478] {taskinstance.py:882} INFO - 
--------------------------------------------------------------------------------
[2021-11-29 23:35:27,485] {taskinstance.py:901} INFO - Executing <Task(SparkSubmitOperator): transform_twitter_aluraonline> on 2021-11-24T09:00:00+00:00
[2021-11-29 23:35:27,486] {standard_task_runner.py:54} INFO - Started process 3131 to run task
[2021-11-29 23:35:27,536] {standard_task_runner.py:77} INFO - Running: ['airflow', 'run', 'twitter_dag', 'transform_twitter_aluraonline', '2021-11-24T09:00:00+00:00', '--job_id', '14', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/twitter_dag.py', '--cfg_path', '/tmp/tmpr_ufh631']
[2021-11-29 23:35:27,536] {standard_task_runner.py:78} INFO - Job 14: Subtask transform_twitter_aluraonline
[2021-11-29 23:35:27,554] {logging_mixin.py:112} INFO - Running <TaskInstance: twitter_dag.transform_twitter_aluraonline 2021-11-24T09:00:00+00:00 [running]> on host kauai-VirtualBox
[2021-11-29 23:35:27,612] {base_hook.py:89} INFO - Using connection to: id: spark_default. Host: local, Port: None, Schema: None, Login: None, Password: None, extra: XXXXXXXX
[2021-11-29 23:35:27,613] {spark_submit_hook.py:325} INFO - Spark-Submit cmd: /opt/spark/bin/spark-submit --master local --name twitter_transformation /home/kauai/spark/transformation.py --src /home/kauai/kauai/datapipeline/datalake/bronze/twitter_aluraonline/extract_date=2021-11-24 --dest /home/kauai/kauai/datapipeline/datalake/silver/twitter_aluraonline/ --process-date 2021-11-24
[2021-11-29 23:35:30,787] {spark_submit_hook.py:479} INFO - 21/11/29 23:35:30 WARN Utils: Your hostname, kauai-VirtualBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)
[2021-11-29 23:35:30,788] {spark_submit_hook.py:479} INFO - 21/11/29 23:35:30 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
[2021-11-29 23:35:30,814] {spark_submit_hook.py:479} INFO - WARNING: An illegal reflective access operation has occurred
[2021-11-29 23:35:30,814] {spark_submit_hook.py:479} INFO - WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)
[2021-11-29 23:35:30,814] {spark_submit_hook.py:479} INFO - WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
[2021-11-29 23:35:30,814] {spark_submit_hook.py:479} INFO - WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
[2021-11-29 23:35:30,814] {spark_submit_hook.py:479} INFO - WARNING: All illegal access operations will be denied in a future release
[2021-11-29 23:35:32,002] {spark_submit_hook.py:479} INFO - 21/11/29 23:35:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2021-11-29 23:35:32,866] {spark_submit_hook.py:479} INFO - python3: can't open file '/home/kauai/spark/transformation.py': [Errno 2] No such file or directory
[2021-11-29 23:35:32,890] {spark_submit_hook.py:479} INFO - log4j:WARN No appenders could be found for logger (org.apache.spark.util.ShutdownHookManager).
[2021-11-29 23:35:32,891] {spark_submit_hook.py:479} INFO - log4j:WARN Please initialize the log4j system properly.
[2021-11-29 23:35:32,891] {spark_submit_hook.py:479} INFO - log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
[2021-11-29 23:35:32,952] {taskinstance.py:1150} ERROR - Cannot execute: /opt/spark/bin/spark-submit --master local --name twitter_transformation /home/kauai/spark/transformation.py --src /home/kauai/kauai/datapipeline/datalake/bronze/twitter_aluraonline/extract_date=2021-11-24 --dest /home/kauai/kauai/datapipeline/datalake/silver/twitter_aluraonline/ --process-date 2021-11-24. Error code is: 2.
Traceback (most recent call last):
  File "/home/kauai/datapipeline/venv/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 984, in _run_raw_task
    result = task_copy.execute(context=context)
  File "/home/kauai/datapipeline/venv/lib/python3.8/site-packages/airflow/contrib/operators/spark_submit_operator.py", line 187, in execute
    self._hook.submit(self._application)
  File "/home/kauai/datapipeline/venv/lib/python3.8/site-packages/airflow/contrib/hooks/spark_submit_hook.py", line 403, in submit
    raise AirflowException(
airflow.exceptions.AirflowException: Cannot execute: /opt/spark/bin/spark-submit --master local --name twitter_transformation /home/kauai/spark/transformation.py --src /home/kauai/kauai/datapipeline/datalake/bronze/twitter_aluraonline/extract_date=2021-11-24 --dest /home/kauai/kauai/datapipeline/datalake/silver/twitter_aluraonline/ --process-date 2021-11-24. Error code is: 2.
[2021-11-29 23:35:32,958] {taskinstance.py:1187} INFO - Marking task as FAILED. dag_id=twitter_dag, task_id=transform_twitter_aluraonline, execution_date=20211124T090000, start_date=20211130T023527, end_date=20211130T023532
[2021-11-29 23:35:37,466] {local_task_job.py:102} INFO - Task exited with return code 1
